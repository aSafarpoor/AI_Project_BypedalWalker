{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/5lOHHB6llUdeyIFtUGhF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aSafarpoor/AI_Project_BypedalWalker/blob/master/classifier_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read data"
      ],
      "metadata": {
        "id": "xmAcn1bjPL4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "Av4Sn1X2f9-w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t5mRRc34eyhA"
      },
      "outputs": [],
      "source": [
        "def load_txt_file(filename):\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\treturn [int(line.strip()) for line in file]\n",
        "\n",
        "def load_txt_file_for_edges(filename):\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\treturn [list(map(int,line.strip().split())) for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = load_txt_file_for_edges('edges.txt')\n",
        "\n",
        "\n",
        "btrain = load_txt_file('btrain.txt')\n",
        "strain = load_txt_file('strain.txt')\n",
        "\n",
        "\n",
        "btest = load_txt_file('btest.txt')\n",
        "stest = load_txt_file('stest.txt')\n",
        "nodes = list(set(np.array(edges).reshape(-1)))\n",
        "num_nodes = len(nodes)"
      ],
      "metadata": {
        "id": "wwpiM2hPezZy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transductive"
      ],
      "metadata": {
        "id": "t_98W0QGg-XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
        "!pip install torch\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EewAes2_g90b",
        "outputId": "321b599a-7644-4a9b-b404-7936f59a0333"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.utils as pyg_utils\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from torch_geometric.utils import subgraph"
      ],
      "metadata": {
        "id": "qkU4TKqhezeG"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_ETH(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_layers, hidden_width, dropout = True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        input_width = num_node_features\n",
        "        self.num_classes = 2\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.convs.append(GCNConv(input_width, hidden_width, bias=False))\n",
        "            elif i == num_layers - 1:\n",
        "                self.convs.append(GCNConv(hidden_width, self.num_classes, bias=False))\n",
        "            else:\n",
        "                self.convs.append(GCNConv(hidden_width, hidden_width, bias=False))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        h = x\n",
        "        i = 0\n",
        "        for conv in self.convs:\n",
        "            if self.dropout:\n",
        "                h = F.dropout(h, p=0.5, training=self.training)\n",
        "            h = conv(h, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                h = F.tanh(h)\n",
        "            i += 1\n",
        "\n",
        "        return F.log_softmax(h, dim=1)\n"
      ],
      "metadata": {
        "id": "OvLYPRvB3hq2"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT_ETH(torch.nn.Module):\n",
        "    def __init__(self, input_width, num_layers, hidden_width, num_classes, num_heads, dropout: bool = True):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.num_classes = num_classes\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:  # First layer\n",
        "                self.convs.append(GATConv(input_width, hidden_width, heads=num_heads))\n",
        "            elif i == num_layers - 1:  # Last layer\n",
        "                self.convs.append(GATConv(hidden_width * num_heads, self.num_classes, heads=1))\n",
        "            else:  # Middle layers\n",
        "                self.convs.append(GATConv(hidden_width * num_heads, hidden_width, heads=num_heads))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # x = self.conv1(x, edge_index)\n",
        "        # # x = F.elu(x)\n",
        "        # x = F.tanh(x)\n",
        "        # x = self.conv2(x, edge_index)\n",
        "        # h = x\n",
        "\n",
        "        h = x\n",
        "        i = 0\n",
        "        for conv in self.convs:\n",
        "            if self.dropout:\n",
        "                h = F.dropout(h, p=0.5, training=self.training)\n",
        "            h = conv(h, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                h = F.tanh(h)\n",
        "                # h = F.elu(h)\n",
        "            i += 1\n",
        "\n",
        "        return F.log_softmax(h, dim=1)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_r--rexV4MGo"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN1(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim, num_classes):\n",
        "        super(GCN1, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "kd6aMRFVezoO"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN2(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim1, hidden_dim2, num_classes):\n",
        "        super(GCN2, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.softmax(x,dim=1)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "hMuQ41TZso4z"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT1(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim1, hidden_dim2, num_classes, num_heads=1):\n",
        "        super(GAT1, self).__init__()\n",
        "        self.gat1 = GATConv(num_node_features, hidden_dim1, heads=num_heads, concat=True)\n",
        "        self.gat2 = GATConv(hidden_dim1 * num_heads, hidden_dim2, heads=num_heads, concat=True)\n",
        "        self.gat3 = GATConv(hidden_dim2 * num_heads, num_classes, heads=1, concat=False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.gat3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "9RlOZyEMxwz4"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(1, 16)  # 1 input feature, 16 output features\n",
        "        self.conv2 = GCNConv(16, 2)  # 16 input features, 2 output features (binary classification)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHrlHIuqEYIV"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_transductive(model):\n",
        "\n",
        "    edge_index = torch.tensor([[e[0] for e in edges], [e[1] for e in edges]], dtype=torch.long)  # Replace with actual edges\n",
        "\n",
        "\n",
        "    # Assign labels (0 for benign, 1 for sybil)\n",
        "    labels = torch.tensor([0 if i in btrain or i in btest else 1 for i in range(num_nodes)])\n",
        "\n",
        "    # Initialize the node features\n",
        "    x = torch.zeros((num_nodes, 1))  # 1-dimensional embeddings, all zeros initially\n",
        "\n",
        "    # Assign initial embeddings based on the conditions\n",
        "    for node in btrain:\n",
        "        x[node] = 0  # Benign training nodes\n",
        "    for node in strain:\n",
        "        x[node] = 1  # Sybil training nodes\n",
        "    for node in btest + stest:\n",
        "        x[node] = 0.5  # Test nodes\n",
        "\n",
        "    # Create the PyTorch Geometric data object\n",
        "    data = Data(x=x, edge_index=edge_index, y=labels)\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Split data into training and testing masks\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    # Assign masks for training and testing nodes\n",
        "    train_mask[btrain + strain] = True\n",
        "    test_mask[btest + stest] = True\n",
        "\n",
        "    # Training loop\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = loss_fn(out[train_mask], data.y[train_mask])  # Only consider training nodes for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    # Testing function\n",
        "    def test():\n",
        "        model.eval()\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)  # Get predictions\n",
        "        train_acc = accuracy_score(data.y[train_mask].cpu(), pred[train_mask].cpu())\n",
        "        test_acc = accuracy_score(data.y[test_mask].cpu(), pred[test_mask].cpu())\n",
        "        return train_acc, test_acc\n",
        "\n",
        "    # Training the model\n",
        "    epochs = 100\n",
        "    for epoch in range(epochs):\n",
        "        loss = train()\n",
        "        train_acc, test_acc = test()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    train_acc, test_acc = test()\n",
        "    print(f'Final Train Accuracy: {train_acc:.4f}, Final Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "w2SO_Ro26DM4"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oECdI7kYEyPG",
        "outputId": "efecf3f0-10a8-4ffc-f95d-a5caf7a4c5d3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6965, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.6818, Train Acc: 0.8938, Test Acc: 0.8529\n",
            "Epoch 20, Loss: 0.6675, Train Acc: 0.9125, Test Acc: 0.8359\n",
            "Epoch 30, Loss: 0.6428, Train Acc: 0.8938, Test Acc: 0.8514\n",
            "Epoch 40, Loss: 0.6031, Train Acc: 0.8938, Test Acc: 0.8529\n",
            "Epoch 50, Loss: 0.5481, Train Acc: 0.9062, Test Acc: 0.8622\n",
            "Epoch 60, Loss: 0.4827, Train Acc: 0.9125, Test Acc: 0.8746\n",
            "Epoch 70, Loss: 0.4130, Train Acc: 0.9250, Test Acc: 0.8839\n",
            "Epoch 80, Loss: 0.3395, Train Acc: 0.9313, Test Acc: 0.8978\n",
            "Epoch 90, Loss: 0.2675, Train Acc: 0.9750, Test Acc: 0.9226\n",
            "Final Train Accuracy: 0.9812, Final Test Accuracy: 0.9551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN1(num_node_features=1, hidden_dim=16, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE_DwdEsBn2V",
        "outputId": "54aa64d2-55be-4eb3-e3a3-e24cc10ea951"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6669, Train Acc: 0.7125, Test Acc: 0.6285\n",
            "Epoch 10, Loss: 0.6197, Train Acc: 0.9500, Test Acc: 0.9102\n",
            "Epoch 20, Loss: 0.5725, Train Acc: 0.9500, Test Acc: 0.9056\n",
            "Epoch 30, Loss: 0.5173, Train Acc: 0.9563, Test Acc: 0.9102\n",
            "Epoch 40, Loss: 0.4499, Train Acc: 0.9750, Test Acc: 0.9288\n",
            "Epoch 50, Loss: 0.3727, Train Acc: 0.9812, Test Acc: 0.9582\n",
            "Epoch 60, Loss: 0.2958, Train Acc: 0.9875, Test Acc: 0.9768\n",
            "Epoch 70, Loss: 0.2297, Train Acc: 0.9875, Test Acc: 0.9768\n",
            "Epoch 80, Loss: 0.1791, Train Acc: 0.9812, Test Acc: 0.9799\n",
            "Epoch 90, Loss: 0.1433, Train Acc: 0.9812, Test Acc: 0.9783\n",
            "Final Train Accuracy: 0.9812, Final Test Accuracy: 0.9783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN2(num_node_features=1, hidden_dim1=16, hidden_dim2 = 16, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2MjqMzGCDsn",
        "outputId": "edf7886e-87ee-4e4e-a52b-519eece1d33b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6828, Train Acc: 0.6937, Test Acc: 0.6780\n",
            "Epoch 10, Loss: 0.6512, Train Acc: 0.8625, Test Acc: 0.8437\n",
            "Epoch 20, Loss: 0.5903, Train Acc: 0.9062, Test Acc: 0.8762\n",
            "Epoch 30, Loss: 0.5077, Train Acc: 0.9250, Test Acc: 0.9009\n",
            "Epoch 40, Loss: 0.4406, Train Acc: 0.9313, Test Acc: 0.9149\n",
            "Epoch 50, Loss: 0.4064, Train Acc: 0.9437, Test Acc: 0.9195\n",
            "Epoch 60, Loss: 0.3908, Train Acc: 0.9437, Test Acc: 0.9288\n",
            "Epoch 70, Loss: 0.3832, Train Acc: 0.9437, Test Acc: 0.9303\n",
            "Epoch 80, Loss: 0.3789, Train Acc: 0.9500, Test Acc: 0.9334\n",
            "Epoch 90, Loss: 0.3766, Train Acc: 0.9500, Test Acc: 0.9334\n",
            "Final Train Accuracy: 0.9500, Final Test Accuracy: 0.9350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN_ETH(num_node_features=1, num_layers=3, hidden_width=16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9C9qj3ECsBo",
        "outputId": "49b35510-1daa-44e8-f439-c3566f7b9281"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6791, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.6516, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 20, Loss: 0.6497, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 30, Loss: 0.6540, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 40, Loss: 0.6470, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 50, Loss: 0.6540, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 60, Loss: 0.6494, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 70, Loss: 0.6529, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 80, Loss: 0.6550, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 90, Loss: 0.6525, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Final Train Accuracy: 0.5000, Final Test Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT1(num_node_features=1, hidden_dim1=16, hidden_dim2=16, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjzupYgGFBEQ",
        "outputId": "f1b0a7e1-9b23-4225-dd56-61906962757f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6904, Train Acc: 0.5125, Test Acc: 0.5015\n",
            "Epoch 10, Loss: 0.4217, Train Acc: 0.9187, Test Acc: 0.9195\n",
            "Epoch 20, Loss: 0.1939, Train Acc: 0.9688, Test Acc: 0.9489\n",
            "Epoch 30, Loss: 0.1070, Train Acc: 0.9812, Test Acc: 0.9659\n",
            "Epoch 40, Loss: 0.0575, Train Acc: 0.9875, Test Acc: 0.9783\n",
            "Epoch 50, Loss: 0.0277, Train Acc: 0.9938, Test Acc: 0.9845\n",
            "Epoch 60, Loss: 0.0083, Train Acc: 0.9938, Test Acc: 0.9892\n",
            "Epoch 70, Loss: 0.0045, Train Acc: 1.0000, Test Acc: 0.9845\n",
            "Epoch 80, Loss: 0.0034, Train Acc: 1.0000, Test Acc: 0.9861\n",
            "Epoch 90, Loss: 0.0030, Train Acc: 1.0000, Test Acc: 0.9876\n",
            "Final Train Accuracy: 1.0000, Final Test Accuracy: 0.9861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT_ETH(input_width=1, num_layers=4, hidden_width=16, num_classes=2, num_heads=8, dropout= True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYnE_pmhGPxt",
        "outputId": "c5d804ef-d903-4f5a-c440-311e175ff66b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7009, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.6382, Train Acc: 0.6188, Test Acc: 0.5929\n",
            "Epoch 20, Loss: 0.3546, Train Acc: 0.9625, Test Acc: 0.9474\n",
            "Epoch 30, Loss: 0.3648, Train Acc: 1.0000, Test Acc: 0.9969\n",
            "Epoch 40, Loss: 0.3178, Train Acc: 1.0000, Test Acc: 0.9969\n",
            "Epoch 50, Loss: 0.3569, Train Acc: 0.9187, Test Acc: 0.8932\n",
            "Epoch 60, Loss: 0.3195, Train Acc: 0.8375, Test Acc: 0.7771\n",
            "Epoch 70, Loss: 0.3601, Train Acc: 0.9875, Test Acc: 0.9628\n",
            "Epoch 80, Loss: 0.3133, Train Acc: 1.0000, Test Acc: 0.9938\n",
            "Epoch 90, Loss: 0.3191, Train Acc: 0.9125, Test Acc: 0.8545\n",
            "Final Train Accuracy: 0.9875, Final Test Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT1(num_node_features=1, hidden_dim1=4, hidden_dim2=4, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwO2FKuGk3n",
        "outputId": "617593c3-68de-4cb6-86d6-5853873bba2e"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6862, Train Acc: 0.8438, Test Acc: 0.8204\n",
            "Epoch 10, Loss: 0.5923, Train Acc: 0.9125, Test Acc: 0.9009\n",
            "Epoch 20, Loss: 0.4325, Train Acc: 0.9313, Test Acc: 0.9272\n",
            "Epoch 30, Loss: 0.2460, Train Acc: 0.9625, Test Acc: 0.9520\n",
            "Epoch 40, Loss: 0.1311, Train Acc: 0.9750, Test Acc: 0.9582\n",
            "Epoch 50, Loss: 0.0909, Train Acc: 0.9875, Test Acc: 0.9582\n",
            "Epoch 60, Loss: 0.0774, Train Acc: 0.9875, Test Acc: 0.9613\n",
            "Epoch 70, Loss: 0.0649, Train Acc: 0.9875, Test Acc: 0.9659\n",
            "Epoch 80, Loss: 0.0530, Train Acc: 0.9875, Test Acc: 0.9752\n",
            "Epoch 90, Loss: 0.0406, Train Acc: 0.9875, Test Acc: 0.9752\n",
            "Final Train Accuracy: 0.9938, Final Test Accuracy: 0.9845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN2(num_node_features=1, hidden_dim1=6, hidden_dim2 = 6, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jr-H6z3LlKN",
        "outputId": "526fa0b0-eeef-44d2-d7b6-7f8d7714c54b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6912, Train Acc: 0.8000, Test Acc: 0.7771\n",
            "Epoch 10, Loss: 0.6836, Train Acc: 0.9313, Test Acc: 0.9071\n",
            "Epoch 20, Loss: 0.6699, Train Acc: 0.9375, Test Acc: 0.9025\n",
            "Epoch 30, Loss: 0.6475, Train Acc: 0.9062, Test Acc: 0.8777\n",
            "Epoch 40, Loss: 0.6152, Train Acc: 0.9125, Test Acc: 0.8793\n",
            "Epoch 50, Loss: 0.5750, Train Acc: 0.9062, Test Acc: 0.8839\n",
            "Epoch 60, Loss: 0.5299, Train Acc: 0.9313, Test Acc: 0.8947\n",
            "Epoch 70, Loss: 0.4854, Train Acc: 0.9375, Test Acc: 0.9087\n",
            "Epoch 80, Loss: 0.4497, Train Acc: 0.9375, Test Acc: 0.9149\n",
            "Epoch 90, Loss: 0.4253, Train Acc: 0.9375, Test Acc: 0.9164\n",
            "Final Train Accuracy: 0.9375, Final Test Accuracy: 0.9226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#inductive"
      ],
      "metadata": {
        "id": "EWjp8CKGPbuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def create_subgraph(data, nodes_subset):\n",
        "\n",
        "    # Convert nodes_subset to tensor\n",
        "    nodes_subset = torch.tensor(nodes_subset, dtype=torch.long)\n",
        "\n",
        "    # Create a subgraph with only the edges between nodes in nodes_subset\n",
        "    edge_index, edge_attr = subgraph(nodes_subset, data.edge_index, relabel_nodes=True)\n",
        "\n",
        "    # Select the corresponding node features\n",
        "    x = data.x[nodes_subset]\n",
        "\n",
        "    # Select the corresponding labels (if any)\n",
        "    y = data.y[nodes_subset] if data.y is not None else None\n",
        "\n",
        "    # Return the subgraph\n",
        "    subgraph_data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "    return subgraph_data\n",
        "\n",
        "\n",
        "def main_inductive(model):\n",
        "\n",
        "    edge_index = torch.tensor([[e[0] for e in edges], [e[1] for e in edges]], dtype=torch.long)  # Replace with actual edges\n",
        "\n",
        "    # Define the set of unknown nodes (nodes not in btrain, strain, btest, stest)\n",
        "    known_nodes = set(btrain + strain + btest + stest)\n",
        "    unknown_nodes = list(set(range(num_nodes)) - known_nodes)\n",
        "\n",
        "    # Sample 1/4 of unknown nodes for TRAIN\n",
        "    random.shuffle(unknown_nodes)\n",
        "    unknown_sample_for_train = unknown_nodes[:len(unknown_nodes)//4]\n",
        "\n",
        "    # Create subgraph TRAIN consisting of btrain, strain, and 1/4 of unknown nodes\n",
        "    train_nodes = btrain + strain + unknown_sample_for_train\n",
        "\n",
        "    # Create subgraph TEST consisting of the remaining nodes\n",
        "    test_nodes = list(set(range(num_nodes)) - set(train_nodes))\n",
        "\n",
        "    # Assign labels (0 for benign, 1 for sybil)\n",
        "    labels = torch.tensor([0 if i in btrain or i in btest else 1 for i in range(num_nodes)])\n",
        "\n",
        "    # Initialize the node features\n",
        "    x = torch.zeros((num_nodes, 1))  # 1-dimensional embeddings, all zeros initially\n",
        "\n",
        "    # Assign initial embeddings based on the conditions\n",
        "    for node in btrain:\n",
        "        x[node] = 0  # Benign training nodes\n",
        "    for node in strain:\n",
        "        x[node] = 1  # Sybil training nodes\n",
        "    for node in btest + stest:\n",
        "        x[node] = 0.5  # Test nodes\n",
        "\n",
        "    # Create the PyTorch Geometric data object\n",
        "    data = Data(x=x, edge_index=edge_index, y=labels)\n",
        "\n",
        "    # Create subgraphs for training and testing\n",
        "    train_subgraph = create_subgraph(data, train_nodes)\n",
        "    test_subgraph = create_subgraph(data, test_nodes)\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(train_subgraph)\n",
        "        loss = loss_fn(out, train_subgraph.y)  # Only consider training nodes for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    # Testing function\n",
        "    def test():\n",
        "        model.eval()\n",
        "        out = model(test_subgraph)\n",
        "        pred = out.argmax(dim=1)  # Get predictions\n",
        "        test_acc = accuracy_score(test_subgraph.y.cpu(), pred.cpu())\n",
        "        return test_acc\n",
        "\n",
        "    # Training the model\n",
        "    epochs = 500\n",
        "    for epoch in range(epochs):\n",
        "        loss = train()\n",
        "        test_acc = test()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    test_acc = test()\n",
        "    print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_U_XGHAdMUdB"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_inductive(GCN())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38v2yxBQ4W6",
        "outputId": "669a3bc9-ed98-44b8-b137-f43d338c748e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7238, Test Acc: 0.5153\n",
            "Epoch 10, Loss: 0.5275, Test Acc: 0.9042\n",
            "Epoch 20, Loss: 0.3575, Test Acc: 0.9042\n",
            "Epoch 30, Loss: 0.2775, Test Acc: 0.9042\n",
            "Epoch 40, Loss: 0.2726, Test Acc: 0.9042\n",
            "Epoch 50, Loss: 0.2744, Test Acc: 0.9042\n",
            "Epoch 60, Loss: 0.2713, Test Acc: 0.9042\n",
            "Epoch 70, Loss: 0.2705, Test Acc: 0.9042\n",
            "Epoch 80, Loss: 0.2706, Test Acc: 0.9042\n",
            "Epoch 90, Loss: 0.2704, Test Acc: 0.9042\n",
            "Epoch 100, Loss: 0.2703, Test Acc: 0.9042\n",
            "Epoch 110, Loss: 0.2703, Test Acc: 0.9042\n",
            "Epoch 120, Loss: 0.2702, Test Acc: 0.9042\n",
            "Epoch 130, Loss: 0.2701, Test Acc: 0.9042\n",
            "Epoch 140, Loss: 0.2701, Test Acc: 0.9042\n",
            "Epoch 150, Loss: 0.2700, Test Acc: 0.9042\n",
            "Epoch 160, Loss: 0.2700, Test Acc: 0.9042\n",
            "Epoch 170, Loss: 0.2699, Test Acc: 0.9042\n",
            "Epoch 180, Loss: 0.2698, Test Acc: 0.9042\n",
            "Epoch 190, Loss: 0.2698, Test Acc: 0.9042\n",
            "Epoch 200, Loss: 0.2697, Test Acc: 0.9042\n",
            "Epoch 210, Loss: 0.2696, Test Acc: 0.9042\n",
            "Epoch 220, Loss: 0.2696, Test Acc: 0.9042\n",
            "Epoch 230, Loss: 0.2695, Test Acc: 0.9042\n",
            "Epoch 240, Loss: 0.2694, Test Acc: 0.9042\n",
            "Epoch 250, Loss: 0.2694, Test Acc: 0.9042\n",
            "Epoch 260, Loss: 0.2693, Test Acc: 0.9042\n",
            "Epoch 270, Loss: 0.2692, Test Acc: 0.9042\n",
            "Epoch 280, Loss: 0.2691, Test Acc: 0.9042\n",
            "Epoch 290, Loss: 0.2691, Test Acc: 0.9042\n",
            "Epoch 300, Loss: 0.2690, Test Acc: 0.9042\n",
            "Epoch 310, Loss: 0.2689, Test Acc: 0.9042\n",
            "Epoch 320, Loss: 0.2689, Test Acc: 0.9042\n",
            "Epoch 330, Loss: 0.2688, Test Acc: 0.9042\n",
            "Epoch 340, Loss: 0.2687, Test Acc: 0.9042\n",
            "Epoch 350, Loss: 0.2686, Test Acc: 0.9042\n",
            "Epoch 360, Loss: 0.2686, Test Acc: 0.9042\n",
            "Epoch 370, Loss: 0.2685, Test Acc: 0.9042\n",
            "Epoch 380, Loss: 0.2684, Test Acc: 0.9042\n",
            "Epoch 390, Loss: 0.2683, Test Acc: 0.9042\n",
            "Epoch 400, Loss: 0.2683, Test Acc: 0.9042\n",
            "Epoch 410, Loss: 0.2682, Test Acc: 0.9042\n",
            "Epoch 420, Loss: 0.2681, Test Acc: 0.9042\n",
            "Epoch 430, Loss: 0.2681, Test Acc: 0.9042\n",
            "Epoch 440, Loss: 0.2680, Test Acc: 0.9042\n",
            "Epoch 450, Loss: 0.2679, Test Acc: 0.9042\n",
            "Epoch 460, Loss: 0.2678, Test Acc: 0.9042\n",
            "Epoch 470, Loss: 0.2678, Test Acc: 0.9042\n",
            "Epoch 480, Loss: 0.2677, Test Acc: 0.9042\n",
            "Epoch 490, Loss: 0.2676, Test Acc: 0.9042\n",
            "Final Test Accuracy: 0.9042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_inductive(GAT1(num_node_features=1, hidden_dim1=4, hidden_dim2=4, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsIGxzCFQ9Lt",
        "outputId": "c49efad7-e4ed-4b7f-e169-26ca9a5c596d"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7261, Test Acc: 0.8936\n",
            "Epoch 10, Loss: 0.3876, Test Acc: 0.9042\n",
            "Epoch 20, Loss: 0.2960, Test Acc: 0.9042\n",
            "Epoch 30, Loss: 0.2693, Test Acc: 0.9042\n",
            "Epoch 40, Loss: 0.2702, Test Acc: 0.9042\n",
            "Epoch 50, Loss: 0.2668, Test Acc: 0.9042\n",
            "Epoch 60, Loss: 0.2658, Test Acc: 0.9042\n",
            "Epoch 70, Loss: 0.2655, Test Acc: 0.9042\n",
            "Epoch 80, Loss: 0.2654, Test Acc: 0.9042\n",
            "Epoch 90, Loss: 0.2653, Test Acc: 0.9042\n",
            "Epoch 100, Loss: 0.2652, Test Acc: 0.9042\n",
            "Epoch 110, Loss: 0.2652, Test Acc: 0.9042\n",
            "Epoch 120, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 130, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 140, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 150, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 160, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 170, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 180, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 190, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 200, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 210, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 220, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 230, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 240, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 250, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 260, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 270, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 280, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 290, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 300, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 310, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 320, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 330, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 340, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 350, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 360, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 370, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 380, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 390, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 400, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 410, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 420, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 430, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 440, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 450, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 460, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 470, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 480, Loss: 0.2651, Test Acc: 0.9042\n",
            "Epoch 490, Loss: 0.2651, Test Acc: 0.9042\n",
            "Final Test Accuracy: 0.9042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sB-1gGrHSvUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}